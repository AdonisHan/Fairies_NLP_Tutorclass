{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\Adonishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import unique_list\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Adonishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Adonishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump', 'NNP'),\n",
       " ('withdraws', 'VBZ'),\n",
       " ('U.S.', 'NNP'),\n",
       " ('from', 'IN'),\n",
       " ('‘', 'JJ'),\n",
       " ('One-Sided', 'JJ'),\n",
       " ('’', 'NN'),\n",
       " ('Iran', 'NNP'),\n",
       " ('Nuclear', 'NNP'),\n",
       " ('Deal', 'NNP')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "text1 = nltk.word_tokenize(\"Trump withdraws U.S. from ‘One-Sided’ Iran Nuclear Deal\")\n",
    "nltk.pos_tag(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('can', 'MD'), ('not', 'RB'), ('bear', 'VB'), ('the', 'DT'), ('pain', 'NN'), ('of', 'IN'), ('bear', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "text=nltk.word_tokenize(\"I cannot bear the pain of bear\")\n",
    "print(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicken/NN'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggedtok = ('chicken', 'NN')\n",
    "from nltk.tag.util import tuple2str\n",
    "tuple2str(taggedtok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 28867),\n",
       " ('VERB', 13564),\n",
       " ('.', 11715),\n",
       " ('ADP', 9857),\n",
       " ('DET', 8725),\n",
       " ('X', 6613),\n",
       " ('ADJ', 6397),\n",
       " ('NUM', 3546),\n",
       " ('PRT', 3219),\n",
       " ('ADV', 3171),\n",
       " ('PRON', 2737),\n",
       " ('CONJ', 2265)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# universal tag set\n",
    "from nltk.corpus import treebank\n",
    "treebank_tagged = treebank.tagged_words(tagset = 'universal')\n",
    "tag = nltk.FreqDist(tag for (word,tag) in treebank_tagged)\n",
    "tag.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nltk.corpus.brown.tagged_sents(categories = 'adventure')[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import unique_list\n",
    "tag_set = unique_list(tag for sent in corpus for (word,tag) in sent)\n",
    "symbols = unique_list(word for sent in corpus for (word,tag) in sent)\n",
    "# print(len(symbols)) # 1908\n",
    "# tag 104\n",
    "trainer = nltk.tag.HiddenMarkovModelTrainer(tag_set, symbols)\n",
    "\n",
    "train_corpus = []\n",
    "test_corpus = []\n",
    "for i in range(len(corpus)):\n",
    "    if i % 10:\n",
    "        train_corpus += [corpus[i]]\n",
    "    else:\n",
    "        test_corpus += [corpus[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(est):\n",
    "    hmm = trainer.train_supervised(train_corpus, estimator = est)\n",
    "    print('%.2f%%' % (100 * hmm.evaluate(test_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
