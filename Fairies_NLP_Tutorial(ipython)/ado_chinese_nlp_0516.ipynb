{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "1. 分词\n",
      "----------------------------------------\n",
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('1. 分词')\n",
    "print('-'*40)\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 默认模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "2. 添加自定义词典/调整词典\n",
      "----------------------------------------\n",
      "如果/放到/post/中/将/出错/。\n",
      "494\n",
      "如果/放到/post/中/将/出错/。\n",
      "「/台中/」/正确/应该/不会/被/切开\n",
      "70\n",
      "「/台中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('2. 添加自定义词典/调整词典')\n",
    "print('-'*40)\n",
    "\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "#如果/放到/post/中将/出错/。\n",
    "print(jieba.suggest_freq(('中', '将'), True))\n",
    "#494\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "#如果/放到/post/中/将/出错/。\n",
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "#「/台/中/」/正确/应该/不会/被/切开\n",
    "print(jieba.suggest_freq('台中', True))\n",
    "#69\n",
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "#「/台中/」/正确/应该/不会/被/切开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "3. 关键词提取\n",
      "----------------------------------------\n",
      " TF-IDF\n",
      "----------------------------------------\n",
      "XX 0.6641537501611111\n",
      "算法 0.48284397217388886\n",
      "遗传算法 0.33207687508055556\n",
      "feature 0.33207687508055556\n",
      "paper 0.33207687508055556\n",
      "能发 0.33207687508055556\n",
      "魔改 0.33207687508055556\n",
      "频域 0.3195217327555555\n",
      "香浓 0.3195217327555555\n",
      "插值 0.3058418303916667\n",
      "本校 0.29165222973055555\n",
      "各种 0.2571122207738889\n",
      "颠覆 0.24639554807166666\n",
      "量子 0.23937427564555558\n",
      "还用 0.2386780542936111\n",
      "定理 0.2260729519222222\n",
      "垃圾 0.22194113910944446\n",
      "图像 0.21545811160694445\n",
      "缺点 0.2118309897425\n",
      "修复 0.2108039678561111\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('3. 关键词提取')\n",
    "print('-'*40)\n",
    "print(' TF-IDF')\n",
    "print('-'*40)\n",
    "\n",
    "s = \"传统图像修复：利用各种feature进行各种空间和频域插值魔改，优点是换一种算法就能发一篇paper，我还见过有些三本校的XX还用量子XX算法和遗传算法，缺点是大部分方法都很垃圾，因为他们都企图颠覆香浓定理。\"\n",
    "for x, w in jieba.analyse.extract_tags(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "3. 关键词提取\n",
      "----------------------------------------\n",
      " TF-IDF\n",
      "----------------------------------------\n",
      "回过头来 0.7316795611090909\n",
      "苦难 0.7316795611090909\n",
      "想想 0.6360845813081818\n",
      "作家 0.605783511440909\n",
      "转换 0.5918071936581818\n",
      "财富 0.5788653495018182\n",
      "经历 0.5233517886545455\n",
      "以前 0.48104112501\n",
      "如今 0.4560691073427273\n",
      "那些 0.4369168080490909\n",
      "已经 0.3109589677854545\n",
      "----------------------------------------\n",
      " TextRank\n",
      "----------------------------------------\n",
      "想想 1.0\n",
      "转换 0.6703672480838158\n",
      "财富 0.666268377692433\n",
      "经历 0.5054612093359121\n",
      "作家 0.4992970809035772\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('3. 关键词提取')\n",
    "print('-'*40)\n",
    "print(' TF-IDF')\n",
    "print('-'*40)\n",
    "\n",
    "s = \"传统图像修复：利用各种feature进行各种空间和频域插值魔改，优点是换一种算法就能发一篇paper，我还见过有些三本校的XX还用量子XX算法和遗传算法，缺点是大部分方法都很垃圾，因为他们都企图颠覆香浓定理。\"\n",
    "for x, w in jieba.analyse.extract_tags(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))\n",
    "\n",
    "print('-'*40)\n",
    "print(' TextRank')\n",
    "print('-'*40)\n",
    "\n",
    "for x, w in jieba.analyse.textrank(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "4. 词性标注\n",
      "----------------------------------------\n",
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('4. 词性标注')\n",
    "print('-'*40)\n",
    "\n",
    "words = jieba.posseg.cut(\"我爱北京天安门\")\n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 종합 - POS(Part of Speech) Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Cut\n",
      "----------------------------------------\n",
      "如今/，/我/当/了/作家/,/回过头来/想想/ /，/以前/经历/的/那些/苦难/已经/转换/为/财富\n",
      "----------------------------------------\n",
      "POS tag\n",
      "----------------------------------------\n",
      "如今 t\n",
      "， x\n",
      "我 r\n",
      "当 p\n",
      "了 ul\n",
      "作家 n\n",
      ", x\n",
      "回过头来 l\n",
      "想想 v\n",
      "  x\n",
      "， x\n",
      "以前 f\n",
      "经历 n\n",
      "的 uj\n",
      "那些 r\n",
      "苦难 a\n",
      "已经 d\n",
      "转换 v\n",
      "为 p\n",
      "财富 n\n",
      "----------------------------------------\n",
      " TF-IDF\n",
      "----------------------------------------\n",
      "回过头来 0.7316795611090909\n",
      "苦难 0.7316795611090909\n",
      "想想 0.6360845813081818\n",
      "作家 0.605783511440909\n",
      "转换 0.5918071936581818\n",
      "财富 0.5788653495018182\n",
      "经历 0.5233517886545455\n",
      "以前 0.48104112501\n",
      "如今 0.4560691073427273\n",
      "那些 0.4369168080490909\n",
      "已经 0.3109589677854545\n",
      "----------------------------------------\n",
      " TextRank\n",
      "----------------------------------------\n",
      "想想 1.0\n",
      "转换 0.6703672480838158\n",
      "财富 0.666268377692433\n",
      "经历 0.5054612093359121\n",
      "作家 0.4992970809035772\n"
     ]
    }
   ],
   "source": [
    "# Part of Speech Analyse in Chinese\n",
    "\n",
    "import jieba.analyse\n",
    "\n",
    "print('-'*40)    \n",
    "print('Cut')\n",
    "print('-'*40)\n",
    "s = \"如今，我当了作家,回过头来想想 ，以前经历的那些苦难已经转换为财富\"\n",
    "print('/'.join(jieba.cut(s, HMM=False)))\n",
    "print('-'*40)\n",
    "print('POS tag')\n",
    "print('-'*40)\n",
    "words = jieba.posseg.cut(\"如今，我当了作家,回过头来想想 ，以前经历的那些苦难已经转换为财富\")\n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))\n",
    "print('-'*40)    \n",
    "print(' TF-IDF')\n",
    "print('-'*40)\n",
    "for x, w in jieba.analyse.extract_tags(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))\n",
    "print('-'*40)    \n",
    "print(' TextRank')\n",
    "print('-'*40)\n",
    "\n",
    "for x, w in jieba.analyse.textrank(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "6. Tokenize: 返回词语在原文的起止位置\n",
      "----------------------------------------\n",
      " 默认模式\n",
      "----------------------------------------\n",
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n",
      "----------------------------------------\n",
      " 搜索模式\n",
      "----------------------------------------\n",
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限\t\t start: 6 \t\t end:8\n",
      "word 公司\t\t start: 8 \t\t end:10\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('6. Tokenize: 返回词语在原文的起止位置')\n",
    "print('-'*40)\n",
    "print(' 默认模式')\n",
    "print('-'*40)\n",
    "\n",
    "result = jieba.tokenize('永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n",
    "\n",
    "print('-'*40)\n",
    "print(' 搜索模式')\n",
    "print('-'*40)\n",
    "\n",
    "result = jieba.tokenize('永和服装饰品有限公司', mode='search')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
